+++
title = 'Babel'
date = 2024-05-14T11:12:37-10:00
+++

Los compañeros con los que estoy haciendo mi proyecto final quieren dejarlo. Estamos intentando [entrenar](https://kaitchup.substack.com/p/datasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa) un LLM para traducir texto, y el [conjunto de datos](https://kaitchup.substack.com/p/datasets-to-train-validate-and-evaluate-machine-translation-d61905d126aa) es demasiado grande para que lo maneje nuestra CPU y RAM. No quiero dejar de fumar. Saber qué hacer con grandes conjuntos de datos es enormemente importante. Les daré mi opinión de que deberían incluir eso en el plan de estudios. Hasta ahora ni el profesor ni los asistentes saben qué hacer, pero estoy seguro de que podemos resolverlo.

Una vez que entrenemos nuestro propio modelo, reemplazaré [la API de Google](https://cloud.google.com/translate?hl=en), que estoy usando actualmente para [generar](https://cloud.google.com/translate?hl=en) contenido en español, francés y noruego a partir de mis publicaciones en inglés.

Hay una versión [avanzada](https://cloud.google.com/translate/docs/intro-to-v3) de la API que estoy usando actualmente y que permite modelos personalizados. Probablemente esté integrado con Google [Cloud Storage](https://cloud.google.com/translate/docs/intro-to-v3). Sería una buena idea para la producción si el presupuesto lo permite, pero para fines educativos, me inclino por construir uno desde cero para practicar, aunque la precisión probablemente sería peor y la infraestructura menos pulida. [Pandas](https://cloud.google.com/translate/docs/intro-to-v3) y [Scikit](https://cloud.google.com/translate/docs/intro-to-v3) proporcionan guías para tratar con grandes conjuntos de datos. Perplexity recomienda usar [Dataflow](https://cloud.google.com/translate/docs/intro-to-v3) y Apache Beam, pero si sigues el [enlace](https://cloud.google.com/translate/docs/intro-to-v3), verás que está obsoleto en Hugging Face. El sitio web enumera [alternativas](https://cloud.google.com/translate/docs/intro-to-v3). Polars se menciona en [Reddit](https://cloud.google.com/translate/docs/intro-to-v3). Curiosamente, Pandas no la menciona como una [biblioteca](https://cloud.google.com/translate/docs/intro-to-v3) recomendada, aunque sí lo es Dask, y se menciona en esta publicación [StackOverflow](https://cloud.google.com/translate/docs/intro-to-v3).

No puedo entender por qué alguna vez fueron castigados por construir esa torre.